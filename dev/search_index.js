var documenterSearchIndex = {"docs":
[{"location":"store/#Store","page":"Data Store","title":"Store","text":"","category":"section"},{"location":"store/","page":"Data Store","title":"Data Store","text":"As many experiments may require a data of data to be preloaded for each trial, Experiment.jl provides a data store that can be initialised once on each worker to reduce the amount of time required for loading the same data.","category":"page"},{"location":"store/","page":"Data Store","title":"Data Store","text":"This store is intended as a read-only store that is reused upon execution of each of the trials. ","category":"page"},{"location":"store/#Usage","page":"Data Store","title":"Usage","text":"","category":"section"},{"location":"store/","page":"Data Store","title":"Data Store","text":"To start, you must create a function which creates the data to be stored, similar to the functions that runs the trial. As en example:","category":"page"},{"location":"store/","page":"Data Store","title":"Data Store","text":"# Goes inside the same file as your experiment run file (i.e. the file that get's included).\nfunction create_global_store(config)\n    # config is the global configuration given to the experiment\n    data = Dict{Symbol, Any}(\n        :dataset => rand(1000),\n        :flag => false,\n        # etc...\n    )\n    return data\nend","category":"page"},{"location":"store/","page":"Data Store","title":"Data Store","text":"The variable config will be the configuration provided to the Experiment struct created for your experiment. Importantly, this function will return a Dict{Symbol, Any}.","category":"page"},{"location":"store/","page":"Data Store","title":"Data Store","text":"The name of this function can be anything, but you need to supply it to the experiment when it is being created, i.e.","category":"page"},{"location":"store/","page":"Data Store","title":"Data Store","text":"experiment = Experiment(\n    name=\"Test Experiment\",\n    include_file=\"run.jl\",\n    function_name=\"run_trial\",\n    init_store_function_name=\"create_global_store\",\n    configuration=config\n)","category":"page"},{"location":"store/","page":"Data Store","title":"Data Store","text":"Inside your run_trial function, you can access the global store using get_global_store","category":"page"},{"location":"store/","page":"Data Store","title":"Data Store","text":"using Experimenter # exports get_global_store\nfunction run_trial(config, trial_id)\n    store = get_global_store()\n    dataset = store[:dataset]\n    # gather your results\n    return results\nend","category":"page"},{"location":"api/#Public-API","page":"Public API","title":"Public API","text":"","category":"section"},{"location":"api/#Database-Management","page":"Public API","title":"Database Management","text":"","category":"section"},{"location":"api/","page":"Public API","title":"Public API","text":"open_db\nexport_db\nrestore_from_db\nmerge_databases!","category":"page"},{"location":"api/#Experimenter.open_db","page":"Public API","title":"Experimenter.open_db","text":"open_db(database_name, [experiment_folder, create_folder]; in_memory=false)\n\nOpens a database and prepares it with the Experimenter.jl schema with tables for Experiment, Trial and Snapshot. If the database already exists, it will open it and not overwrite the existing data.\n\nSetting in_memory to true will skip all of the arguments and create the database \"in memory\" and hence, will not persist.\n\n\n\n\n\n","category":"function"},{"location":"api/#Experimenter.export_db","page":"Public API","title":"Experimenter.export_db","text":"export_db(db::ExperimentDatabase, outfile::AbstractString, experiment_names...)\n\nOpens a new database at outfile and inserts experiments from db into the new db, where the names of the experiment are listed in the final input.\n\n\n\n\n\n","category":"function"},{"location":"api/#Experimenter.restore_from_db","page":"Public API","title":"Experimenter.restore_from_db","text":"restore_from_db(db::ExperimentDatabase, experiment::Experiment)\n\nSearches the db for the supplied experiment, matching on the configuration and the name, disregarding the unique ID.\n\nIf experiment already exists in the db, returns that experiment with the db's UUID for it, otherwise return the input experiment.\n\nWill error if the experiment exists but does not match the input experiment configuration.\n\n\n\n\n\n","category":"function"},{"location":"api/#Experimenter.merge_databases!","page":"Public API","title":"Experimenter.merge_databases!","text":"merge_databases!(primary_db, secondary_db)\n\nSearches all of the records from the secondary database and adds them to the first database.\n\n\n\n\n\n","category":"function"},{"location":"api/#Experiments","page":"Public API","title":"Experiments","text":"","category":"section"},{"location":"api/","page":"Public API","title":"Public API","text":"Experiment\nget_progress\nget_experiment\nget_experiments\nget_experiment_by_name\nget_ratio_completed_trials_by_name","category":"page"},{"location":"api/#Experimenter.Experiment","page":"Public API","title":"Experimenter.Experiment","text":"Experiment\n\nA database object for storing the configuration options of an experiment.\n\nThe signature of the function supplied should be:\n\nfn(configuration::Dict{Symbol, Any}, trial_id::UUID)\n\nThe function should be available when including the file provided.\n\nA name is required to uniquely label this experiment.\n\n\n\n\n\n","category":"type"},{"location":"api/#Experimenter.get_progress","page":"Public API","title":"Experimenter.get_progress","text":"get_progress(db::ExperimentDatabase, name)\n\nReturns a table of the trials of an experiment, identified by the name parameter. Returns details of the progress and configuration, but not the results.\n\n\n\n\n\n","category":"function"},{"location":"api/#Experimenter.get_experiment","page":"Public API","title":"Experimenter.get_experiment","text":"get_experiment(db::ExperimentDatabase, experiment_id)\n\nSearches the db for the given experiment_id which can be given as a string or UUID.\n\n\n\n\n\n","category":"function"},{"location":"api/#Experimenter.get_experiments","page":"Public API","title":"Experimenter.get_experiments","text":"get_experiments(db::ExperimentDatabase)\n\nReturns a vector of all experiments in the database.\n\n\n\n\n\n","category":"function"},{"location":"api/#Experimenter.get_experiment_by_name","page":"Public API","title":"Experimenter.get_experiment_by_name","text":"get_experiment(db::ExperimentDatabase, name)\n\nSearches the db for an experiment with the experiment name set to name. Returns that experiment.\n\n\n\n\n\n","category":"function"},{"location":"api/#Experimenter.get_ratio_completed_trials_by_name","page":"Public API","title":"Experimenter.get_ratio_completed_trials_by_name","text":"get_ratio_completed_trials_by_name(db::ExperimentDatabase, name)\n\nCalculates the ratio of completed trials for the given experiment with name name, without fetching the results.\n\n\n\n\n\n","category":"function"},{"location":"api/#Data-Storage","page":"Public API","title":"Data Storage","text":"","category":"section"},{"location":"api/","page":"Public API","title":"Public API","text":"get_global_store\nget_results_from_trial_global_database","category":"page"},{"location":"api/#Experimenter.get_global_store","page":"Public API","title":"Experimenter.get_global_store","text":"get_global_store()\n\nTries to get the global store that is initialised by the supplied function with the name specified by init_store_function_name set in  the running experiment. This store is local to each worker.\n\nSetup\n\nTo create the store, add a function in your include file which returns a dictionary of type Dict{Symbol, Any}, which has the signature similar to:\n\nfunction create_global_store(config)\n    # config is the global configuration given to the experiment\n    data = Dict{Symbol, Any}(\n        :dataset => rand(1000),\n        :flag => false,\n        # etc...\n    )\n    return data\nend\n\nInside your main experiment execution function, you can get this store via get_global_store, which is exported by Experimenter.\n\nfunction myrunner(config, trial_id)\n    store = get_global_store()\n    dataset = store[:dataset] # Retrieve the keys from the store\n    # process data\n    return results\nend\n\n\n\n\n\n","category":"function"},{"location":"api/#Experimenter.get_results_from_trial_global_database","page":"Public API","title":"Experimenter.get_results_from_trial_global_database","text":"get_results_from_trial_global_database(trial_id::UUID)\n\nGets the results of a specific trial from the global database. Redirects to the master node if on a worker node. Locks to secure access.\n\n\n\n\n\n","category":"function"},{"location":"api/#Trials","page":"Public API","title":"Trials","text":"","category":"section"},{"location":"api/","page":"Public API","title":"Public API","text":"get_trial\nget_trials\nget_trials_by_name\nget_trials_ids_by_name","category":"page"},{"location":"api/#Experimenter.get_trial","page":"Public API","title":"Experimenter.get_trial","text":"get_trial(db::ExperimentDatabase, trial_id)\n\nGets the trial with the matching trial_id (string or UUID) from the database.\n\n\n\n\n\n","category":"function"},{"location":"api/#Experimenter.get_trials","page":"Public API","title":"Experimenter.get_trials","text":"get_trial(db::ExperimentDatabase, experiment_id)\n\nGets all trials from the database under the experiment_id supplied.\n\n\n\n\n\n","category":"function"},{"location":"api/#Experimenter.get_trials_by_name","page":"Public API","title":"Experimenter.get_trials_by_name","text":"get_trials_by_name(db::ExperimentDatabase, name)\n\nGets all trials from the database for the experiment with the name name.\n\n\n\n\n\n","category":"function"},{"location":"api/#Experimenter.get_trials_ids_by_name","page":"Public API","title":"Experimenter.get_trials_ids_by_name","text":"get_trials_ids_by_name(db::ExperimentDatabase, name)\n\nGets just the trial IDs from the database for the experiment with the name name.\n\n\n\n\n\n","category":"function"},{"location":"api/#Execution","page":"Public API","title":"Execution","text":"","category":"section"},{"location":"api/","page":"Public API","title":"Public API","text":"@execute\nSerialMode\nMultithreadedMode\nDistributedMode\nHeterogeneousMode\nMPIMode","category":"page"},{"location":"api/#Experimenter.@execute","page":"Public API","title":"Experimenter.@execute","text":"@execute experiment database [mode=SerialMode use_progress=false directory=pwd()]\n\nRuns the experiment out of global scope, saving results in the database, skipping all already executed trials.\n\nArgs:\n\nmode: Specifies SerialMode, MultithreadedMode or DistributedMode to execute serially or in parallel. use_progress: Shows a progress bar directory: Directory to change the current process (or worker processes) to for execution.\n\n\n\n\n\n","category":"macro"},{"location":"api/#Experimenter.ExecutionModes.SerialMode","page":"Public API","title":"Experimenter.ExecutionModes.SerialMode","text":"Executes the trials of the experiment one of the other, sequentially.\n\n\n\n\n\n","category":"type"},{"location":"api/#Experimenter.ExecutionModes.MultithreadedMode","page":"Public API","title":"Experimenter.ExecutionModes.MultithreadedMode","text":"Executes the trials of the experiment in parallel using Threads.@Threads\n\n\n\n\n\n","category":"type"},{"location":"api/#Experimenter.ExecutionModes.DistributedMode","page":"Public API","title":"Experimenter.ExecutionModes.DistributedMode","text":"Executes the trials of the experiment in parallel using Distributed.jls pmap.\n\n\n\n\n\n","category":"type"},{"location":"api/#Experimenter.ExecutionModes.HeterogeneousMode","page":"Public API","title":"Experimenter.ExecutionModes.HeterogeneousMode","text":"Executes the trials of the experiment in parallel using a custom scheduler that uses all threads of each worker.\n\n\n\n\n\n","category":"type"},{"location":"api/#Experimenter.ExecutionModes.MPIMode","page":"Public API","title":"Experimenter.ExecutionModes.MPIMode","text":"Executes the trials of the experiment in parallel using MPI, which uses one MPI node for coordination and saving of jobs.\n\n\n\n\n\n","category":"type"},{"location":"api/#Cluster-Management","page":"Public API","title":"Cluster Management","text":"","category":"section"},{"location":"api/","page":"Public API","title":"Public API","text":"Experimenter.Cluster.init\n","category":"page"},{"location":"api/#Experimenter.Cluster.init","page":"Public API","title":"Experimenter.Cluster.init","text":"init(; kwargs...)\n\nChecks the environment variables to see if a script is running on a cluster  and then launches the processes as determined by the environment variables.\n\nArguments\n\nThe keyword arguments are forwarded to the init function for each cluster management system. Check the ext folder for extensions to see which keywords are supported.\n\n\n\n\n\n","category":"function"},{"location":"api/#Snapshots","page":"Public API","title":"Snapshots","text":"","category":"section"},{"location":"api/","page":"Public API","title":"Public API","text":"get_snapshots\nlatest_snapshot\nsave_snapshot!\nget_latest_snapshot_from_global_database\nsave_snapshot_in_global_database","category":"page"},{"location":"api/#Experimenter.get_snapshots","page":"Public API","title":"Experimenter.get_snapshots","text":"get_snapshots(db::ExperimentDatabase, trial_id)\n\nGets all the associated snapshots (as a vector) from the database for a given trial with matching trial_id.\n\n\n\n\n\n","category":"function"},{"location":"api/#Experimenter.latest_snapshot","page":"Public API","title":"Experimenter.latest_snapshot","text":"latest_snapshot(db::ExperimentDatabase, trial_id)\n\nGets the latest snapshot from the database for a given trial with matching trial_id, using the date of the most recent snapshot.\n\nKnown to have issues when snapshots are created within the same second.\n\n\n\n\n\n","category":"function"},{"location":"api/#Experimenter.save_snapshot!","page":"Public API","title":"Experimenter.save_snapshot!","text":"save_snapshot!(db::ExperimentDatabase, trial_id::UUID, state::Dict{Symbol,Any}, [label])\n\nSaves the snapshot with given state in the database, associating with the trial with matching trial_id. Automatically saves the time of the snapshot.\n\n\n\n\n\n","category":"function"},{"location":"api/#Experimenter.get_latest_snapshot_from_global_database","page":"Public API","title":"Experimenter.get_latest_snapshot_from_global_database","text":"get_latest_snapshot_from_global_database(trial_id::UUID)\n\nSame as get_latest_snapshot, but in the given global database. Redirects to the master worker if on a distributed node. Only works when using @execute.\n\n\n\n\n\n","category":"function"},{"location":"api/#Experimenter.save_snapshot_in_global_database","page":"Public API","title":"Experimenter.save_snapshot_in_global_database","text":"save_snapshot_in_global_database(trial_id::UUID, state, [label])\n\nSave the results of a specific trial from the global database, with the supplied state and optional label. Redirects to the master node if on a worker node. Locks to secure access.\n\n\n\n\n\n","category":"function"},{"location":"api/#Misc","page":"Public API","title":"Misc","text":"","category":"section"},{"location":"api/","page":"Public API","title":"Public API","text":"LinearVariable\nLogLinearVariable\nRepeatVariable\nIterableVariable\nMatchIterableVariable","category":"page"},{"location":"api/#Experimenter.LinearVariable","page":"Public API","title":"Experimenter.LinearVariable","text":"LinearVariable(min, max, n)\n\nSpecifies a range for a parameter variable to take, from min to max inclusive with n total values.\n\n\n\n\n\n","category":"type"},{"location":"api/#Experimenter.LogLinearVariable","page":"Public API","title":"Experimenter.LogLinearVariable","text":"LogLinearVariable(min, max, n)\n\nA linearly spaced parameter variable in log space. If min=1 and max=100 and n=3 then the values are [1,10,100].\n\n\n\n\n\n","category":"type"},{"location":"api/#Experimenter.RepeatVariable","page":"Public API","title":"Experimenter.RepeatVariable","text":"RepeatVariable(val, n)\n\nSpecifies a parameter variable that outputs the same value val n times. \n\n\n\n\n\n","category":"type"},{"location":"api/#Experimenter.IterableVariable","page":"Public API","title":"Experimenter.IterableVariable","text":"IterableVariable(iter)\n\nWraps a given iterator iter to tell the experiment to perform a grid search over each element of the iterator for the given parameter.\n\n\n\n\n\n","category":"type"},{"location":"api/#Experimenter.MatchIterableVariable","page":"Public API","title":"Experimenter.MatchIterableVariable","text":"MatchIterableVariable(iter)\n\nThis type of variable matches with the product from the other AbstractVariables in the configuration.\n\nThis does not form part of the product variables (grid search), but instead uniques matches with that product.\n\n\n\n\n\n","category":"type"},{"location":"snapshots/#Custom-Snapshots","page":"Custom Snapshots","title":"Custom Snapshots","text":"","category":"section"},{"location":"snapshots/","page":"Custom Snapshots","title":"Custom Snapshots","text":"Most simulated experiments take a long time to run, and may be cancelled part way. It is important to be able to save progress on these long-running simulations. For this example, we will take the idea of simulating a Monte-Carlo process. Imagine that your process looks like the below function: ","category":"page"},{"location":"snapshots/","page":"Custom Snapshots","title":"Custom Snapshots","text":"using Random\nfunction run_simulation(config::Dict{Symbol, Any}, trial_id)\n    epochs = config[:epochs]\n    T = Float64\n    positions = zeros(T, epochs)\n    x = zero(T)\n    for t in 2:epochs\n        x += randn(T)\n        positions[t] = x\n    end\n\n    results = Dict{Symbol, Any}(\n        mean_position => sum(positions) / length(positions)\n    )\n    return results\nend","category":"page"},{"location":"snapshots/","page":"Custom Snapshots","title":"Custom Snapshots","text":"If we want to be able to replicate this process, we should take in a seed for the random values and save a snapshot every so often:","category":"page"},{"location":"snapshots/","page":"Custom Snapshots","title":"Custom Snapshots","text":"using Random\nusing Experimenter\nfunction run_simulation(config::Dict{Symbol, Any}, trial_id)\n    epochs = config[:epochs]\n    seed = config[:seed]\n    snapshot_interval = config[:snapshot_interval]\n    snapshot_label = config[:snapshot_label]\n\n    rng = Random.Xoshiro(seed)\n    T = Float64\n    positions = zeros(T, epochs)\n    x = zero(T)\n    for t in 2:epochs\n        x += randn(rng, T)\n        positions[t] = x\n        if t % snapshot_interval == 0\n            state = Dict{Symbol, Any}(\n                :rng_state => copy(rng),\n                :positions => positions[begin:t]\n            )\n            # Global will only work when executing globally with @execute!\n            save_snapshot_in_global_database(trial_id, state, snapshot_label)\n        end\n    end\n\n    results = Dict{Symbol, Any}(\n        :mean_position => sum(positions) / length(positions)\n    )\n    return results\nend","category":"page"},{"location":"snapshots/","page":"Custom Snapshots","title":"Custom Snapshots","text":"This will save a snapshot associated with the trial_id supplied, whose key is based on the current time. So far, we have only saved the snapshot, but we should implement a method which initialises our simulation, loading from snapshot:","category":"page"},{"location":"snapshots/","page":"Custom Snapshots","title":"Custom Snapshots","text":"using Logging\nfunction init_sim(config::Dict{Symbol,Any}, trial_id)\n    snapshot = get_latest_snapshot_from_global_database(trial_id)\n\n    rng = Random.Xoshiro(config[:seed])\n    T = Float64\n    positions = zeros(T, config[:epochs])\n    x = zero(T)\n    start_t = 2\n    if !isnothing(snapshot)\n        state = snapshot.state # Dict we saved earlier\n        copy!(rng, state[:rng_state]) # Reset RNG\n        saved_positions = state[:positions]\n        # Load existing positions\n        positions[begin:length(saved_positions)] .= saved_positions\n        x = last(saved_positions)\n        start_t = length(saved_positions) + 1\n        @info \"Restored trial $trial_id from snapshot - $(length(saved_positions)) epochs restored.\"\n    end\n\n    return x, positions, start_t, rng, T\nend","category":"page"},{"location":"snapshots/","page":"Custom Snapshots","title":"Custom Snapshots","text":"Finally, we put it altogether:","category":"page"},{"location":"snapshots/","page":"Custom Snapshots","title":"Custom Snapshots","text":"# saved in `run.jl`\nusing Random\nusing Experimenter\nfunction run_simulation(config::Dict{Symbol, Any}, trial_id)\n    epochs = config[:epochs]\n    snapshot_interval = config[:snapshot_interval]\n    snapshot_label = config[:snapshot_label]\n\n    x, positions, start_t, rng, T = init_sim(config, trial_id)\n\n    for t in start_t:epochs\n        x += randn(rng, T)\n        positions[t] = x\n\n        if t % snapshot_interval == 0\n            state = Dict{Symbol, Any}(\n                :rng_state => copy(rng),\n                :positions => positions[begin:t]\n            )\n            # Global will only work when executing globally with @execute!\n            save_snapshot_in_global_database(trial_id, state, snapshot_label)\n        end\n    end\n\n    results = Dict{Symbol, Any}(\n        :mean_position => sum(positions) / length(positions)\n    )\n    return results\nend\n# ... include definiton for init_sim function.","category":"page"},{"location":"snapshots/","page":"Custom Snapshots","title":"Custom Snapshots","text":"Now we can create a script to execute this project:","category":"page"},{"location":"snapshots/","page":"Custom Snapshots","title":"Custom Snapshots","text":"using Experimenter\n\nconfig = Dict{Symbol, Any}(\n    :seed => IterableVariable([1234,4567,8910]),\n    :epochs => IterableVariable([500_000, 1_000_000]),\n    :snapshot_interval => 100_000,\n    :snapshot_label => \"MC Snapshots\"\n)\nexperiment = Experiment(\n    name=\"Snapshot Experiment\",\n    include_file=\"run.jl\",\n    function_name=\"run_simulation\",\n    configuration=deepcopy(config)\n)\ndb = open_db(\"experiments.db\")\n@execute experiment db SerialMode true","category":"page"},{"location":"snapshots/","page":"Custom Snapshots","title":"Custom Snapshots","text":"You can use Ctrl+C to cancel the execution before it is complete, and run again to see if the logger has been triggered (i.e. a snapshot has been loaded). If the program runs too quickly, try adding a sleep(0.1) whenever a snapshot is saved, so you get a chance to cancel it to see if it works.","category":"page"},{"location":"getting_started/#Getting-Started","page":"Getting Started","title":"Getting Started","text":"","category":"section"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"Experimenter.jl is a package that is designed to help you keep track of your experiments and their results. It is built to work with Distributed.jl for parallel writing of results to a SQLite database file.","category":"page"},{"location":"getting_started/#Opening-the-database","page":"Getting Started","title":"Opening the database","text":"","category":"section"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"To get started, first import the library with:","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"using Experimenter","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"After this one needs to create a database to store the results:","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"db = open_db(\"experiments.db\")","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"One can always supply a given directory for the database as well, for example:","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"db = open_db(\"experiments.db\", joinpath(pwd(), \"results\"))","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"The first call to open_db will check if a file already exists. If the file does not exist, Experimenter.jl will create the file and the schema for the database.","category":"page"},{"location":"getting_started/#Defining-the-work-we-want-to-process","page":"Getting Started","title":"Defining the work we want to process","text":"","category":"section"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"To run an experiment we need to first define a function which runs our experiment:","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"# in run.jl\nusing Random\nfunction run_trial(config::Dict{Symbol,Any}, trial_id)\n    results = Dict{Symbol, Any}()\n    sigma = config[:sigma]\n    N = config[:N]\n    seed = config[:seed]\n    rng = Random.Xoshiro(seed)\n    # Perform some calculation\n    results[:distance] = sum(rand(rng) * sigma for _ in 1:N)\n    # Must return a Dict{Symbol, Any}, with the data we want to save\n    return results\nend","category":"page"},{"location":"getting_started/#Creating-an-experiment","page":"Getting Started","title":"Creating an experiment","text":"","category":"section"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"Now we can define a configuration for our experiment:","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"# in a script\nconfig = Dict{Symbol,Any}(\n    :N => IterableVariable([10, 20]),\n    :seed => IterableVariable([1234, 4321]),\n    :sigma => 1.0\n)","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"This is just a dictionary, with some special wrappers IterableVariable for some of the config values. When we create our experiment, we pass in this configuration and the path to the file with the function to run our experiment:","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"experiment = Experiment(\n    name=\"Test Experiment\",\n    include_file=\"run.jl\",\n    function_name=\"run_trial\",\n    configuration=deepcopy(config)\n)","category":"page"},{"location":"getting_started/#Examining-the-trials-of-an-experiment","page":"Getting Started","title":"Examining the trials of an experiment","text":"","category":"section"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"We can look at the set of trials this experiment will create:","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"for trial in experiment\n    println(trial.configuration)\nend\n# Dict{Symbol, Any}(:N => 10, :sigma => 1.0, :seed => 1234)\n# Dict{Symbol, Any}(:N => 20, :sigma => 1.0, :seed => 1234)\n# Dict{Symbol, Any}(:N => 10, :sigma => 1.0, :seed => 4321)\n# Dict{Symbol, Any}(:N => 20, :sigma => 1.0, :seed => 4321)","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"or, alternatively:","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"trials = collect(experiment)","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"There are multiple trials in this experiment as we used an IterableVariable wrapper, which says that we want to run a grid search over these specific variables.","category":"page"},{"location":"getting_started/#Executing-an-experiment","page":"Getting Started","title":"Executing an experiment","text":"","category":"section"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"To execute our experiment, we use the @execute macro. To execute the experiment serially:","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"@execute experiment db SerialMode","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"Instead of SerialMode, we can use ThreadedMode to execute via Threads.@threads, or use DistributedMode to execute via a pmap and run across different workers.","category":"page"},{"location":"getting_started/#Getting-the-results","page":"Getting Started","title":"Getting the results","text":"","category":"section"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"Once the experiments are completed, we can run:","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"trials = get_trials_by_name(db, \"Test Experiment\");","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"This will return a Vector{Trial}, where Trial has a results field which is the dictionary we returned from the run_trial function. To get the results we write:","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"results = [t.results for t in trials]","category":"page"},{"location":"getting_started/#Re-running-failed-trials","page":"Getting Started","title":"Re-running failed trials","text":"","category":"section"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"If a trial did not finish, then the results field will be missing. Whenever we run the @execute macro, it will skip any trial that already has results, and only run the next trials. Therefore ","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"@execute experiment db SerialMode","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"will not run any more trials, as they have already been completed. However, if the execution stopped (for example killed by the SLURM scheduler due to wall time), then it will only run the trials that have not been completed.","category":"page"},{"location":"getting_started/#Saving-part-way","page":"Getting Started","title":"Saving part way","text":"","category":"section"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"If your trials take a long time to finish and may be cancelled during their run, you can always implement a way to save a Snapshot, which allows you to save data you need to restore a trial part way through running. An example setup for doing this is given in Custom Snapshots.","category":"page"},{"location":"getting_started/#What-is-an-Experiment?","page":"Getting Started","title":"What is an Experiment?","text":"","category":"section"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"An experiment sets up a configuration that specifies (by default) a grid search over variables. If none of the special classes such as IterableVariable, LinearVariable, LogLinearVariable etc are used as values in the configuration dictionary, this will specify only a single trial. However, if these special types are used, an experiment will have multiple trials, whose configurations are created via a grid search over the special AbstractVariables provided, with each of these values being replaced by a single element in these iterables.","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"As an example the following configuration:","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"config = Dict{Symbol, Any}(\n    :a => IterableVariable([\"a\", \"b\"]),\n    :b => LinearVariable(1, 4, 5),\n    :c => \"constant value\"\n)","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"Since the first two parts are marked with a type of AbstractVariable (or concrete type of), these will form our grid search. The actual configurations will look like the following code:","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"for a in [\"a\", \"b\"]\n    for b in LinRange(1, 4, 5)\n        trial_config = Dict{Symbol, Any}(\n            :a => a,\n            :b => b,\n            :c => \"constant value\"\n        )\n    end\nend","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"A matched variable will not form part of the grid, but works as follows:","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"matched = rand(2*5)\ni = 1\nfor a in [\"a\", \"b\"]\n    for b in LinRange(1, 4, 5)\n        trial_config = Dict{Symbol, Any}(\n            :a => a,\n            :b => b,\n            :c => \"constant value\",\n            :matched => matched[i]\n        )\n        i += 1\n    end\nend","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"The matched variable must have as many entries as there are in the grid search.","category":"page"},{"location":"clusters/#Cluster-Execution","page":"Cluster Execution","title":"Cluster Execution","text":"","category":"section"},{"location":"clusters/","page":"Cluster Execution","title":"Cluster Execution","text":"This package is most useful for running grid search trials on a cluster environment (i.e. a HPC), or a single node with many CPUs. ","category":"page"},{"location":"clusters/","page":"Cluster Execution","title":"Cluster Execution","text":"There are two main ways you can distribute your experiment over many processes - DistributedMode or MPIMode. ","category":"page"},{"location":"clusters/","page":"Cluster Execution","title":"Cluster Execution","text":"For those using a distributed cluster, we recommend that you launch your jobs using the MPI functionality, instead of the legacy SLURM support (see the SLURM section below for details).","category":"page"},{"location":"clusters/#MPI","page":"Cluster Execution","title":"MPI","text":"","category":"section"},{"location":"clusters/#Installation","page":"Cluster Execution","title":"Installation","text":"","category":"section"},{"location":"clusters/","page":"Cluster Execution","title":"Cluster Execution","text":"Most HPC environments have access to their own MPI implementation. These MPI implementations often take advantage of proprietary interconnect (networking) between the nodes that allow for low-latency and high-throughput communication. If you would like to find your local HPC's implementation, you may be able to look through the catalogue via a bash terminal, using the Environment Modules package available on most HPC systems:","category":"page"},{"location":"clusters/","page":"Cluster Execution","title":"Cluster Execution","text":"module avail","category":"page"},{"location":"clusters/","page":"Cluster Execution","title":"Cluster Execution","text":"or, for a more directed search:","category":"page"},{"location":"clusters/","page":"Cluster Execution","title":"Cluster Execution","text":"module spider mpi","category":"page"},{"location":"clusters/","page":"Cluster Execution","title":"Cluster Execution","text":"You may have multiple versions. If you are unsure as to which version to use, check the documentation for the HPC, contact your local System Administrator or simply use what is available. Using OpenMPI is often a reliable choice. ","category":"page"},{"location":"clusters/","page":"Cluster Execution","title":"Cluster Execution","text":"You can load which version of MPI you would like by adding","category":"page"},{"location":"clusters/","page":"Cluster Execution","title":"Cluster Execution","text":"module load mpi/latest","category":"page"},{"location":"clusters/","page":"Cluster Execution","title":"Cluster Execution","text":"to your job script (remember to change mpi/latest to the package available on your system).","category":"page"},{"location":"clusters/","page":"Cluster Execution","title":"Cluster Execution","text":"Make you have loaded the MPI version you wish to use by running the module load ... command in the same terminal before opening Julia in the terminal by using","category":"page"},{"location":"clusters/","page":"Cluster Execution","title":"Cluster Execution","text":"julia --project","category":"page"},{"location":"clusters/","page":"Cluster Execution","title":"Cluster Execution","text":"Run this command in the same directory as your project.","category":"page"},{"location":"clusters/","page":"Cluster Execution","title":"Cluster Execution","text":"Now, you have to add the MPI package to your local environment using","category":"page"},{"location":"clusters/","page":"Cluster Execution","title":"Cluster Execution","text":"import Pkg; Pkg.add(\"MPI\")","category":"page"},{"location":"clusters/","page":"Cluster Execution","title":"Cluster Execution","text":"Now you should be able to load MPIPreferences and tell MPI about using your system binary:","category":"page"},{"location":"clusters/","page":"Cluster Execution","title":"Cluster Execution","text":"using MPI.MPIPreferences\n\nMPIPreferences.use_system_binary()\nexit()","category":"page"},{"location":"clusters/","page":"Cluster Execution","title":"Cluster Execution","text":"This should create a new LocalPreferences.toml file. I would recommend adding this file to your .gitignore list and not committing it to your GitHub repository.","category":"page"},{"location":"clusters/#Job-Scripts","page":"Cluster Execution","title":"Job Scripts","text":"","category":"section"},{"location":"clusters/","page":"Cluster Execution","title":"Cluster Execution","text":"When you are running on a cluster, write your job script so that you load MPI and precompile Julia before launching your job. An example job script could look like the following:","category":"page"},{"location":"clusters/","page":"Cluster Execution","title":"Cluster Execution","text":"#!/bin/bash\n\n#SBATCH --ntasks=8\n#SBATCH --cpus-per-task=4\n#SBATCH --mem-per-cpu=2048\n#SBATCH --time=00:30:00\n#SBATCH -o mpi_job_%j.out\n\n\nmodule load mpi/latest\nmodule load julia/1.10.2\n\n# Precompile Julia first to avoid race conditions\njulia --project --threads=4 -e 'import Pkg; Pkg.instantiate()'\njulia --project --threads=4 -e 'import Pkg; Pkg.precompile()'\n\nmpirun -n 8 julia --project --threads=4 my_experiment.jl","category":"page"},{"location":"clusters/","page":"Cluster Execution","title":"Cluster Execution","text":"Use the above as a template and change the specifics to suit your specific workload and HPC.","category":"page"},{"location":"clusters/","page":"Cluster Execution","title":"Cluster Execution","text":"info: Info\nMake sure that you launch your jobs with at least 2 processes (tasks), as one task is dedicated towards coordinating the execution of trials and saving the results.","category":"page"},{"location":"clusters/#Experiment-file","page":"Cluster Execution","title":"Experiment file","text":"","category":"section"},{"location":"clusters/","page":"Cluster Execution","title":"Cluster Execution","text":"As usual, you should write a script to define your experiment and run the configuration. Below is an example, where it is assumed there is another file called run.jl which contains a function run_trial which takes a configuration dictionary and a trial UUID.","category":"page"},{"location":"clusters/","page":"Cluster Execution","title":"Cluster Execution","text":"using Experimenter\n\nconfig = Dict{Symbol,Any}(\n    :N => IterableVariable([Int(1e6), Int(2e6), Int(3e6)]),\n    :seed => IterableVariable([1234, 4321, 3467, 134234, 121]),\n    :sigma => 0.0001)\nexperiment = Experiment(\n    name=\"Test Experiment\",\n    include_file=\"run.jl\",\n    function_name=\"run_trial\",\n    configuration=deepcopy(config)\n)\n\ndb = open_db(\"experiments.db\")\n\n# Init the cluster\nExperimenter.Cluster.init()\n\n@execute experiment db MPIMode(1)","category":"page"},{"location":"clusters/","page":"Cluster Execution","title":"Cluster Execution","text":"Note that we are calling MPIMode(1) which says that we want a communication batch size of 1. If your jobs are small, and you want each worker to process a batch at a time, you can set this to a higher number.","category":"page"},{"location":"clusters/#SLURM","page":"Cluster Execution","title":"SLURM","text":"","category":"section"},{"location":"clusters/","page":"Cluster Execution","title":"Cluster Execution","text":"warning: Warning\nIt is recommended that you use the above MPI mode to run jobs on a cluster, instead of relying on ClusterManagers.jl, as it is much slower to run jobs.","category":"page"},{"location":"clusters/","page":"Cluster Execution","title":"Cluster Execution","text":"Normally when running on SLURM, one creates a bash script to tell the scheduler about the resource requirements for a job. The following is an example:","category":"page"},{"location":"clusters/","page":"Cluster Execution","title":"Cluster Execution","text":"#!/bin/bash\n\n#SBATCH --nodes=2\n#SBATCH --ntasks=2\n#SBATCH --cpus-per-task=2\n#SBATCH --mem-per-cpu=1024\n#SBATCH --time=00:30:00\n#SBATCH -o hpc/output/test_job_%j.out","category":"page"},{"location":"clusters/","page":"Cluster Execution","title":"Cluster Execution","text":"The function [Experimenter.Cluster.create_slurm_template] provides an easy way to create one of these bash scripts with everything you need to run.","category":"page"},{"location":"clusters/#Example","page":"Cluster Execution","title":"Example","text":"","category":"section"},{"location":"clusters/","page":"Cluster Execution","title":"Cluster Execution","text":"Let us take the following end-to-end example. Say that we have an experiment script at my_experiment.jl (contents below), which now initialises the cluster:","category":"page"},{"location":"clusters/","page":"Cluster Execution","title":"Cluster Execution","text":"using Experimenter\n\nconfig = Dict{Symbol,Any}(\n    :N => IterableVariable([Int(1e6), Int(2e6), Int(3e6)]),\n    :seed => IterableVariable([1234, 4321, 3467, 134234, 121]),\n    :sigma => 0.0001)\nexperiment = Experiment(\n    name=\"Test Experiment\",\n    include_file=\"run.jl\",\n    function_name=\"run_trial\",\n    configuration=deepcopy(config)\n)\n\ndb = open_db(\"experiments.db\")\n\n# Init the cluster\nExperimenter.Cluster.init()\n\n@execute experiment db DistributedMode","category":"page"},{"location":"clusters/","page":"Cluster Execution","title":"Cluster Execution","text":"Additionally, we have the file run.jl containing:","category":"page"},{"location":"clusters/","page":"Cluster Execution","title":"Cluster Execution","text":"using Random\nusing Distributed\nfunction run_trial(config::Dict{Symbol,Any}, trial_id)\n    results = Dict{Symbol, Any}()\n    sigma = config[:sigma]\n    N = config[:N]\n    seed = config[:seed]\n    rng = Random.Xoshiro(seed)\n    # Perform some calculation\n    results[:distance] = sum(rand(rng) * sigma for _ in 1:N)\n    results[:num_threads] = Threads.nthreads()\n    results[:hostname] = gethostname()\n    results[:pid] = Distributed.myid()\n    # Must return a Dict{Symbol, Any}, with the data we want to save\n    return results\nend","category":"page"},{"location":"clusters/","page":"Cluster Execution","title":"Cluster Execution","text":"We can now create a bash script to run our experiment. We create a template by running the following in the terminal (or adjust or the REPL)","category":"page"},{"location":"clusters/","page":"Cluster Execution","title":"Cluster Execution","text":"julia --project -e 'using Experimenter; Experimenter.Cluster.create_slurm_template(\"myrun.sh\")'","category":"page"},{"location":"clusters/","page":"Cluster Execution","title":"Cluster Execution","text":"We then modify the create myrun.sh file to the following:","category":"page"},{"location":"clusters/","page":"Cluster Execution","title":"Cluster Execution","text":"#!/bin/bash\n\n#SBATCH --ntasks=4\n#SBATCH --cpus-per-task=2\n#SBATCH --mem-per-cpu=1024\n#SBATCH --time=00:30:00\n#SBATCH -o hpc/logs/job_%j.out\n\njulia --project --threads=1 my_experiment.jl\n\n# Optional: Remove the files created by ClusterManagers.jl\nrm -fr julia-*.out\n","category":"page"},{"location":"clusters/","page":"Cluster Execution","title":"Cluster Execution","text":"Once written, we execute this on the cluster via","category":"page"},{"location":"clusters/","page":"Cluster Execution","title":"Cluster Execution","text":"sbatch myrun.sh","category":"page"},{"location":"clusters/","page":"Cluster Execution","title":"Cluster Execution","text":"We can then open a Julia REPL (once the job has finished) to see the results:","category":"page"},{"location":"clusters/","page":"Cluster Execution","title":"Cluster Execution","text":"using Experimenter\ndb = open_db(\"experiments.db\")\ntrials = get_trials_by_name(db, \"Test Experiment\")\n\nfor (i, t) in enumerate(trials)\n    hostname = t.results[:hostname]\n    id = t.results[:pid]\n    println(\"Trial $i ran on $hostname on worker $id\")\nend","category":"page"},{"location":"clusters/","page":"Cluster Execution","title":"Cluster Execution","text":"Support for running on SLURM is based on this gist available on GitHub. This gist also provides information on how to adjust the SLURM script to allow for one GPU to be allocated to each worker.","category":"page"},{"location":"execution/#Running-your-Experiments","page":"Running your Experiments","title":"Running your Experiments","text":"","category":"section"},{"location":"execution/","page":"Running your Experiments","title":"Running your Experiments","text":"Once you have created an experiment you can run it with the @execute macro supplied by Experimenter.jl, suppose you already have an experiment stored in the experiment variable and a database opened with the variable db, then you can execute simply with:","category":"page"},{"location":"execution/","page":"Running your Experiments","title":"Running your Experiments","text":"@execute experiment db SerialMode","category":"page"},{"location":"execution/","page":"Running your Experiments","title":"Running your Experiments","text":"Which will only execute trials from the experiment that have not been completed. It is up to you to implement how to continue your simulations from snapshots, using the Snapshots API. ","category":"page"},{"location":"execution/#Single-Node-Parallel","page":"Running your Experiments","title":"Single Node Parallel","text":"","category":"section"},{"location":"execution/","page":"Running your Experiments","title":"Running your Experiments","text":"There are two main ways of executing your experiments in parallel: multithreading (Threads) or multiprocessing (Distributed). The former has lower latency, but the latter scales to working on across a cluster. The easiest option if you are executing on a single computer, use:","category":"page"},{"location":"execution/","page":"Running your Experiments","title":"Running your Experiments","text":"@execute experiment db MultithreadedMode","category":"page"},{"location":"execution/","page":"Running your Experiments","title":"Running your Experiments","text":"By default, this will use as many threads as you have enabled. You can set this using the environment variable JULIA_NUM_THREADS, or by starting Julia with --threads=X, replacing X with the number you want. You can check what your current setting is with Threads.nthreads().","category":"page"},{"location":"execution/","page":"Running your Experiments","title":"Running your Experiments","text":"Alternatively, we can change the execution mode to DistributedMode:","category":"page"},{"location":"execution/","page":"Running your Experiments","title":"Running your Experiments","text":"@execute experiment db DistributedMode","category":"page"},{"location":"execution/","page":"Running your Experiments","title":"Running your Experiments","text":"This internally uses pmap from the Distributed.jl standard library, parallelising across all open workers. You can check the number of distributed workers with:","category":"page"},{"location":"execution/","page":"Running your Experiments","title":"Running your Experiments","text":"using Distributed\nnworkers()","category":"page"},{"location":"execution/","page":"Running your Experiments","title":"Running your Experiments","text":"Experimenter.jl will not spin up processes for you, this is something you have to do yourself, see Distributed Execution for an in depth example.","category":"page"},{"location":"execution/","page":"Running your Experiments","title":"Running your Experiments","text":"info: Info\nIf your code has many memory allocations, it may be better to use DistributedMode instead of MultithreadedMode.","category":"page"},{"location":"execution/#Heterogeneous-Execution","page":"Running your Experiments","title":"Heterogeneous Execution","text":"","category":"section"},{"location":"execution/","page":"Running your Experiments","title":"Running your Experiments","text":"If you want each distributed worker to be able to run multiple jobs at the same time, you can select a heterogeneous execution scheduling mode, which will allow each worker to run multiple trials simultaneously using multithreading. An example use case for this is where you have multiple nodes, each with many cores, and you do not wish to pay the memory cost from each separate process. Additionally, you can load data in a single process which can be reused by each execution in the same process. This mode may also allow multiple trials to share resources, such as a GPU, which typically only supports one process.","category":"page"},{"location":"execution/","page":"Running your Experiments","title":"Running your Experiments","text":"To run this, you simply change the mode to the HeterogeneousMode option, providing the number of threads to use on each worker, e.g.","category":"page"},{"location":"execution/","page":"Running your Experiments","title":"Running your Experiments","text":"@execute experiment db HeterogeneousMode(2)","category":"page"},{"location":"execution/","page":"Running your Experiments","title":"Running your Experiments","text":"which will allow each distributed worker to run two trials simultaneously via multithreading. If this option is selected, it is encouraged that you enable multiple threads per worker when launching the process, e.g. with addprocs:","category":"page"},{"location":"execution/","page":"Running your Experiments","title":"Running your Experiments","text":"addprocs(4; exeflags=[\"--threads=2\"])","category":"page"},{"location":"execution/","page":"Running your Experiments","title":"Running your Experiments","text":"Otherwise, each worker may only have access to a single thread and the overall performance throughput will be worse.","category":"page"},{"location":"execution/#MPI-Execution","page":"Running your Experiments","title":"MPI Execution","text":"","category":"section"},{"location":"execution/","page":"Running your Experiments","title":"Running your Experiments","text":"Most HPC clusters use a Message Passing Interface implementation to handle communication between different processes and synchronise tasks. Experimenter.jl now has built-in support for execution via MPI, which has much lower overhead than the built-in Distributed.jl multiprocessing library. See more examples in the Cluster Execution page. ","category":"page"},{"location":"distributed/#Distributed-Execution","page":"Distributed Execution","title":"Distributed Execution","text":"","category":"section"},{"location":"distributed/","page":"Distributed Execution","title":"Distributed Execution","text":"If you want to execute on a single node, but using multiprocessing (i.e. Distributed.jl), then you can start Julia with","category":"page"},{"location":"distributed/","page":"Distributed Execution","title":"Distributed Execution","text":"julia --project -p 8","category":"page"},{"location":"distributed/","page":"Distributed Execution","title":"Distributed Execution","text":"To start Julia with 8 workers. Alternatively, you can add processes while running:","category":"page"},{"location":"distributed/","page":"Distributed Execution","title":"Distributed Execution","text":"using Distributed\naddprocs(8)","category":"page"},{"location":"distributed/","page":"Distributed Execution","title":"Distributed Execution","text":"As long as nworkers() show more than one worker, then your execution of trials will occur in parallel, across these workers.","category":"page"},{"location":"distributed/","page":"Distributed Execution","title":"Distributed Execution","text":"Once the workers have been added, make sure to change your execution mode to DistributedMode to take advantage of the parallelism.","category":"page"},{"location":"distributed/","page":"Distributed Execution","title":"Distributed Execution","text":"If you have access to a HPC cluster and would like to use multiple nodes, you can do this easily with Experimenter.jl - see more in Cluster Execution.","category":"page"},{"location":"","page":"Home","title":"Home","text":"CurrentModule = Experimenter","category":"page"},{"location":"#Experimenter","page":"Home","title":"Experimenter","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"A package for easily running experiments for different parameters and saving the results in a centralised database","category":"page"},{"location":"#Package-Features","page":"Home","title":"Package Features","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Create a local SQLite database to store the results of your experiment, removing the need to keep track of 1000s of results files for each parameter configuration.\nProvides a standard structure for executing code across a range of parameters.\nProvides saving of results into the database using standard Julia types.\nPromotes writing a script that can be easily committed to a Git repository to keep track of results and parameters used throughout development.\nProvides an @execute macro that will execute an experiment (consisting of many trials with different parameters). Can execute serially, or in parallel with a choice of multithreading or multiprocessing or even MPI mode.\nProvides an easy way to execute trials across a High Performance Cluster (HPC).\nAutomatically skips completed trials, and provides a Snapshots API to allow for partial progress to be saved and reloaded.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Head over to Getting Started to get an overview of this package.","category":"page"},{"location":"#Manual-Outline","page":"Home","title":"Manual Outline","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Pages = [\n    \"getting_started.md\",\n    \"execution.md\",\n    \"distributed.md\",\n    \"clusters.md\",\n    \"store.md\",\n    \"snapshots.md\",\n]\nDepth = 2","category":"page"},{"location":"","page":"Home","title":"Home","text":"Check out the API at Public API.","category":"page"}]
}
